{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Credentialed Accounts\n",
      "ACTIVE  ACCOUNT\n",
      "*       yang.zhou.yzu@gmail.com\n",
      "\n",
      "To set the active account, run:\n",
      "    $ gcloud config set account `ACCOUNT`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/Users/zhouyang/Downloads/google-cloud-sdk/bin/gcloud auth list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/zhouyang/Downloads/google-cloud-sdk/bin/gcloud services enable texttospeech.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=UozaMteqF4x3tPDgKXbbTuD13uo1gU&access_type=offline&code_challenge=RlkN28gtx4z3GHFe95h0alQN3U1RwAsqyAtILQX-uNY&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [/Users/zhouyang/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"genuine-segment-253508\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "!/Users/zhouyang/Downloads/google-cloud-sdk/bin/gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (8.14.0)\n",
      "Collecting google-cloud-texttospeech\n",
      "  Downloading google_cloud_texttospeech-2.14.1-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: backcall in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (4.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from ipython) (0.1.3)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 (from google-cloud-texttospeech)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-texttospeech)\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m140.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-texttospeech)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m594.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m915.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests<3.0.0.dev0,>=2.18.0 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading grpcio-1.56.0-cp39-cp39-macosx_10_10_universal2.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading grpcio_status-1.56.0-py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from stack-data->ipython) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from stack-data->ipython) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/zhouyang/anaconda3/envs/comp_net/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Downloading charset_normalizer-3.2.0-cp39-cp39-macosx_10_9_x86_64.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-texttospeech)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Installing collected packages: urllib3, pyasn1, protobuf, idna, grpcio, charset-normalizer, certifi, cachetools, rsa, requests, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-api-core, google-cloud-texttospeech\n",
      "Successfully installed cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.2.0 google-api-core-2.11.1 google-auth-2.22.0 google-cloud-texttospeech-2.14.1 googleapis-common-protos-1.59.1 grpcio-1.56.0 grpcio-status-1.56.0 idna-3.4 proto-plus-1.22.3 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 rsa-4.9 urllib3-1.26.16\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import google.cloud.texttospeech as tts\n",
    "\n",
    "\n",
    "def unique_languages_from_voices(voices: Sequence[tts.Voice]):\n",
    "    language_set = set()\n",
    "    for voice in voices:\n",
    "        for language_code in voice.language_codes:\n",
    "            language_set.add(language_code)\n",
    "    return language_set\n",
    "\n",
    "\n",
    "def list_languages():\n",
    "    client = tts.TextToSpeechClient()\n",
    "    response = client.list_voices()\n",
    "    languages = unique_languages_from_voices(response.voices)\n",
    "\n",
    "    print(f\" Languages: {len(languages)} \".center(60, \"-\"))\n",
    "    for i, language in enumerate(sorted(languages)):\n",
    "        print(f\"{language:>10}\", end=\"\\n\" if i % 5 == 4 else \"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Languages: 57 -----------------------\n",
      "     af-ZA     ar-XA     bg-BG     bn-IN     ca-ES\n",
      "    cmn-CN    cmn-TW     cs-CZ     da-DK     de-DE\n",
      "     el-GR     en-AU     en-GB     en-IN     en-US\n",
      "     es-ES     es-US     eu-ES     fi-FI    fil-PH\n",
      "     fr-CA     fr-FR     gl-ES     gu-IN     he-IL\n",
      "     hi-IN     hu-HU     id-ID     is-IS     it-IT\n",
      "     ja-JP     kn-IN     ko-KR     lt-LT     lv-LV\n",
      "     ml-IN     mr-IN     ms-MY     nb-NO     nl-BE\n",
      "     nl-NL     pa-IN     pl-PL     pt-BR     pt-PT\n",
      "     ro-RO     ru-RU     sk-SK     sr-RS     sv-SE\n",
      "     ta-IN     te-IN     th-TH     tr-TR     uk-UA\n",
      "     vi-VN    yue-HK"
     ]
    }
   ],
   "source": [
    "list_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.texttospeech as tts\n",
    "\n",
    "\n",
    "def text_to_wav(voice_name: str, text: str):\n",
    "    language_code = \"-\".join(voice_name.split(\"-\")[:2])\n",
    "    text_input = tts.SynthesisInput(text=text)\n",
    "    voice_params = tts.VoiceSelectionParams(\n",
    "        language_code=language_code, name=voice_name\n",
    "    )\n",
    "    audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)\n",
    "\n",
    "    client = tts.TextToSpeechClient()\n",
    "    response = client.synthesize_speech(\n",
    "        input=text_input,\n",
    "        voice=voice_params,\n",
    "        audio_config=audio_config,\n",
    "    )\n",
    "\n",
    "    filename = f\"{voice_name}.wav\"\n",
    "    with open(filename, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print(f'Generated speech saved to \"{filename}\"')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated speech saved to \"en-US-News-K.wav\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Voices: 105 ------------------------\n",
      "en-AU    | en-AU-Neural2-A          | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Neural2-B          | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Neural2-C          | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Neural2-D          | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-News-E             | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-News-F             | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-News-G             | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Polyglot-1         | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-B         | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-B         | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-D         | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Standard-D         | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Wavenet-A          | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Wavenet-B          | MALE     | 24,000 Hz\n",
      "en-AU    | en-AU-Wavenet-C          | FEMALE   | 24,000 Hz\n",
      "en-AU    | en-AU-Wavenet-D          | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Neural2-A          | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Neural2-B          | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Neural2-C          | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Neural2-D          | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Neural2-F          | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-News-G             | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-News-H             | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-News-I             | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-News-J             | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-News-K             | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-News-L             | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-News-M             | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-B         | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-B         | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-D         | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-D         | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-F         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Standard-F         | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Wavenet-A          | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Wavenet-B          | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Wavenet-C          | FEMALE   | 24,000 Hz\n",
      "en-GB    | en-GB-Wavenet-D          | MALE     | 24,000 Hz\n",
      "en-GB    | en-GB-Wavenet-F          | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-A         | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-B         | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-B         | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-C         | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-C         | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-D         | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Standard-D         | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Wavenet-A          | FEMALE   | 24,000 Hz\n",
      "en-IN    | en-IN-Wavenet-B          | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Wavenet-C          | MALE     | 24,000 Hz\n",
      "en-IN    | en-IN-Wavenet-D          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-A          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Neural2-C          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-D          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Neural2-E          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-F          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-G          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-H          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Neural2-I          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Neural2-J          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-News-K             | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-News-L             | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-News-M             | MALE     | 24,000 Hz\n",
      "en-US    | en-US-News-N             | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Polyglot-1         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-A         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-A         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-B         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-B         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-C         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-D         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-D         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-E         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-E         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-F         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-F         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-G         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-G         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-H         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-H         | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Standard-I         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-I         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-J         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Standard-J         | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Studio-M           | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Studio-O           | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-A          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-B          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-C          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-D          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-E          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-F          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-G          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-H          | FEMALE   | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-I          | MALE     | 24,000 Hz\n",
      "en-US    | en-US-Wavenet-J          | MALE     | 24,000 Hz\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.texttospeech as tts\n",
    "\n",
    "\n",
    "def list_voices(language_code=None):\n",
    "    client = tts.TextToSpeechClient()\n",
    "    response = client.list_voices(language_code=language_code)\n",
    "    voices = sorted(response.voices, key=lambda voice: voice.name)\n",
    "\n",
    "    print(f\" Voices: {len(voices)} \".center(60, \"-\"))\n",
    "    for voice in voices:\n",
    "        languages = \", \".join(voice.language_codes)\n",
    "        name = voice.name\n",
    "        gender = tts.SsmlVoiceGender(voice.ssml_gender).name\n",
    "        rate = voice.natural_sample_rate_hertz\n",
    "        print(f\"{languages:<8} | {name:<24} | {gender:<8} | {rate:,} Hz\")\n",
    "        \n",
    "list_voices(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated speech saved to \"en-US-Wavenet-I.wav\"\n"
     ]
    }
   ],
   "source": [
    "text_to_wav(\"en-US-Wavenet-I\", \"\"\"\n",
    "Hi everyone, the paper that I’m going to present is titled.\n",
    "\n",
    "Synthesizing Speech Test Cases with Text-to-Speech?. An Empirical Study on the False Alarms in Automated Speech Recognition Testing.\n",
    "\n",
    "We find that there are up to 52% of failed test cases found by state-of-the-art speech testing tools are false alarms.\n",
    "\n",
    "I’m Zhou Yang, a PhD student at Singapore Management University. This is a collaborative work done by researchers at SMU and Monash Malaysia.\n",
    "\n",
    "Automated Speech Recognition, as suggested by its name, tries to automatically convert a piece of audio, into transcripts\n",
    "\n",
    "The ASR techniques have been widely adopted in our daily life. \n",
    "For example, Hey Siri. \n",
    "We can also input text using our voice.\n",
    "We have 3 papers about autonomous driving in this session.\n",
    "ASR systems can also be deployed in cars to recognize voice commands like asking your car to navigate to a certain location.\n",
    "\n",
    "Typically there will be a “however” if a presenter say so many good things.\n",
    "\n",
    "So, however, A-S-R is not perfect.\n",
    "One offensive example is that the YouTube auto caption system inappropriately transcribes audio for kids into offensive contents.\n",
    "I won’t read it out. So I just give you 10 seconds and you can read in mind. \n",
    "\n",
    "Another example is that researchers shows that actually low-quality ASR in car cause more cognitive distractions to drivers, which may cause serious accidents.\n",
    "\n",
    "So, it is important to test ASR systems.\n",
    "The test case consists of two parts, audio, and its corresponding ground truth transcripts.\n",
    "\n",
    "Depending on what you have, there are two ways to create speech test cases manually.\n",
    "If you have audio, for example, many records of conversation, just ask people to transcribe.\n",
    "If you have text, for example, a lot of books, just ask people to read it out.\n",
    "\n",
    "However, this manual process can be rather expensive.\n",
    "In some cases, it’s not like oh I ask a group of people to read the content.\n",
    "Assuming that we want to test ASR’s ability in recognizing medical audio, we may need experts to label the data, which can be costly.\n",
    "This motivates us to synthesize speech test cases automatically.\n",
    "\n",
    "One way is to use transformations to synthesize audio.\n",
    "Given the original audio, we can apply a combination of different transformations, like add background noise, change the volume, add perturbation, change the speed, and many others.\n",
    "After the transformations, we obtain new audio.\n",
    "There is a metamorphic relationship here.\n",
    "The audio after slight transformation, sounds almost the same to human, so ASR should recognize them as the same transcripts!\n",
    "\n",
    "Another way is to automate the test case generation process is to use the text-to-speech technique.\n",
    "In the manual testing process, \n",
    "Text is converted into audio, and an ASR system transcribes the audio. \n",
    "The oracle is that the original text and the transcriptions should be the same.\n",
    "\n",
    "If we ask another person to read the text out, the relationship still holds.\n",
    "\n",
    "Another person, still holds.\n",
    "\n",
    "Then, what about asking another AI model, called text-to-speech model, to convert the text into audio, and let the ASR to transcribe.\n",
    "This new metamorphic relationship forms the foundation of using TTS system to automatically generate speech test cases.\n",
    "\n",
    "But a potential problem is that, the generated audio itself can be invalid. In other words, a TTS model cannot pronounce texts correctly.\n",
    "\n",
    "In this case, if an ASR doesn’t correctly transcribe the generated audio, we cannot decide whether it is because the ASR is not functional or it is because the TTS is not functional.\n",
    "\n",
    "Previous works use the framework of differential testing to mitigate the problem.\n",
    "There are many ASR systems available.\n",
    "We feed the generated audio into multiple ASR systems, if at least one of them can correctly transcribe, it means that the audio is valid.\n",
    "In this case, if an ASR system cannot produce the correct transcription, we find a failed test case.\n",
    "\n",
    "But if all the ASR systems cannot correctly transcribe, we still cannot decide which part of this pipeline has problem. \n",
    "So we call such audio as interminable test case.\n",
    "\n",
    "We tried to use this pipeline to test 4 ASR systems.\n",
    "Given the same budget, which means that the same number of generated audio, we find thousands of failed test cases for them.\n",
    "The results look promising. \n",
    "We can find so many failures automatically in a cheap way, as generate audio using TTS is generally much cheaper than human labeling.\n",
    "\n",
    "Again, when we say good things, there is a However.\n",
    "However, a question to ask is that does the synthetic failures reflect actual failures. \n",
    "As there are differences between the audio pronounced by humans and TTS systems, in terms of different aspects like …\n",
    "Maybe an ASR system cannot recognize TTS-generated audio, but it can correctly recognize human speech.\n",
    "We call this case as “false alarms.”\n",
    "And we care about how many false alarms we have when testing ASR systems using TTS.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "str2='''\n",
    "\n",
    "In this empirical study, we use two widely used datasets that come with both text and audio.\n",
    "We only use texts for generating test cases, and the audio is only used to evaluate false alarms.\n",
    "We experiment with 5 popular ASR systems that demonstrate state-of-the-art performance, and 4 TTS system, covering both commercial ones like Google TTS and open-source ones.\n",
    "\n",
    "The first question we try to explore is that “How notable is the performance difference between ASR systems when transcribing human audio and TTS-generated audio?”\n",
    "We use a metric called “average word error rate” to measure ASR performance on a set of test cases.\n",
    "The rightmost figures show performance on human audio.\n",
    "We can observe that in general, performance on audio generated by GlowTTS and Google TTS are closer to that on human audio.\n",
    "While ASR performance on Espeak and Festival generated audio is far worse than the performance on human audio.\n",
    "\n",
    "This lead to another question, How prevalent are false alarms when using TTS-generated audio to test ASR systems?\n",
    "In the figure, we use the false alarm rate as a metric, meaning the ratio of false alarms in all the failed test cases.\n",
    "\n",
    "From this figure, we can first observe that false alarms are common in the ASR testing scenario!\n",
    "When testing Wav2Vec model using the Espeak, over 50% of failed test cases are false alarms.\n",
    "\n",
    "We can also observe that the choice of TTS to generate audio makes a difference in false alarms.\n",
    "Using Google TTS to generate audio produce the least number of false alarms across all the ASR systems and 2 datasets.\n",
    "\n",
    "GoogleTTS appears to be the most effective speech synthesizer!\n",
    "\n",
    "Then, we manually sample false alarms and listen to them to summarize some patterns that cause false alarms.\n",
    "We find that in some cases, ASR systems cannot pronounce consonants prominently.\n",
    "For example, it may pronounce “officers” as “offices”\n",
    "ASR systems may not pronounce suffixes clearly.\n",
    "Besides, they may not pronounce grammatical clearly.\n",
    "For example, they easily mis pronounce “as” to “is”.\n",
    " \n",
    "\n",
    " In some case, TTS systems pronounce in a correct way.\n",
    "But ASR systems fail to recognize.\n",
    "For example, ASRs fail to transcribe some homophones or fail to transcribe words with multiple pronunciations.\n",
    "\n",
    "Since there are many false alarms, we wonder whether we can build a predictor to find the texts that are more likely to be false alarms in advance.\n",
    "\n",
    "So we split all the test cases into 3 sets: 60% training data, 10% validation data, and 30% testing data.\n",
    "Each text will produce 20 pieces of audio, as we have 4 TTS systems and 5 ASR systems.\n",
    "If over 10 audio are false alarms, we label it as 1.\n",
    "Otherwise, we label it as 0.\n",
    "\n",
    "Then, we train an RNN-based estimator that takes the text as input, and produce the proability that this text leads to false alarms.\n",
    "On the testing set, we find that the estimator performs well. It have over 93% precision and over 97% F-1 score.\n",
    "\n",
    "\n",
    "In conclusion, this empirical study shows that using synthetic audio to test ASR can result in many false alarms.\n",
    "Choosing high-quality TTS (like me) can better estimate ASR performance.\n",
    "This paper also trains an RNN-based estimator to predict false alarms.\n",
    "In the future, the authors believe that it is promising to extend the work to more ASR and TTS systems.\n",
    "\n",
    "\n",
    "Hope it inspires you.\n",
    "You may wonder how this lazy guy standing near the desk can use TTS to answer questions.\n",
    "The truth is that he cannot.\n",
    "So ask as much as you can. \n",
    "Any questions are welcome.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated speech saved to \"en-US-Wavenet-I.wav\"\n"
     ]
    }
   ],
   "source": [
    "text_to_wav(\"en-US-Wavenet-I\", str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated speech saved to \"en-US-Studio-O.wav\"\n"
     ]
    }
   ],
   "source": [
    "text_to_wav(\"en-US-Studio-O\", '''Hope it inspires you.\n",
    "You may wonder how this lazy guy standing near the desk can use TTS to answer questions.\n",
    "The truth is that he cannot.\n",
    "So just smash him with as many questions as you can. \n",
    "Any questions are welcome.\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
